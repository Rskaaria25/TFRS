{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjvfmeK5WzZB"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-recommenders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "6XgWt07AW4pG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('/content/food_test.csv')\n",
        "\n",
        "# Preprocessing the dataset\n",
        "data['Tipe'] = data['Tipe 1'] + ',' + data['Tipe 2'] + ',' + data['Tipe 3']\n",
        "data['Tipe'] = data['Tipe'].str.lower()\n",
        "\n",
        "# Vectorizing pre-processed food type plots using TF-IDF\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(data['Tipe'])\n",
        "\n",
        "# Finding cosine similarity between vectors\n",
        "similarity_matrix = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "# Define the FoodRecommenderModel\n",
        "class FoodRecommenderModel(tf.keras.Model):\n",
        "    def __init__(self, num_food_names, num_food_types, embedding_dim=32, hidden_units=[64, 32]):\n",
        "        super(FoodRecommenderModel, self).__init__()\n",
        "        self.food_name_embedding = Embedding(num_food_names, embedding_dim)\n",
        "        self.food_type_embedding = Embedding(num_food_types, embedding_dim)\n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(units, activation='relu') for units in hidden_units\n",
        "        ])\n",
        "        self.decoder = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(units, activation='relu') for units in reversed(hidden_units[:-1])\n",
        "        ])\n",
        "        self.output_layer = tf.keras.layers.Dense(num_food_names, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        food_names = inputs['food_names']\n",
        "        food_types = inputs['food_types']\n",
        "        \n",
        "        food_name_embeddings = self.food_name_embedding(food_names)\n",
        "        food_type_embeddings = self.food_type_embedding(food_types)\n",
        "        concatenated_embeddings = tf.keras.layers.concatenate([food_name_embeddings, food_type_embeddings], axis=1)\n",
        "        encoded = self.encoder(concatenated_embeddings)\n",
        "        decoded = self.decoder(encoded)\n",
        "        logits = self.output_layer(decoded)\n",
        "        return logits\n",
        "\n",
        "# Define the function to get recommendations\n",
        "def get_recommendations_by_types(food_types, similarity_matrix, k=10):\n",
        "    food_indices = []\n",
        "    for food_type in food_types:\n",
        "        indices = data[data['Tipe'].str.contains(food_type)].index\n",
        "        food_indices.extend(indices)\n",
        "    food_indices = list(set(food_indices))\n",
        "    \n",
        "    similarity_scores = list(enumerate(similarity_matrix[food_indices].sum(axis=0)))\n",
        "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "    top_k_food_indices = [i for i, _ in similarity_scores[1:k+1]]\n",
        "    top_k_food_names = data.loc[top_k_food_indices, 'Nama'].values\n",
        "    return top_k_food_names\n",
        "\n",
        "# Create the StringLookup layers for food names and types\n",
        "food_name_vocab = StringLookup()\n",
        "food_name_vocab.adapt(data['Nama'].values)\n",
        "food_type_vocab = StringLookup()\n",
        "food_type_vocab.adapt(data['Tipe'].values)\n",
        "\n",
        "# Convert the input data to TensorFlow Dataset\n",
        "def convert_to_dataset(names, types):\n",
        "    names = food_name_vocab(names)\n",
        "    types = food_type_vocab(types)\n",
        "    return tf.data.Dataset.from_tensor_slices((names, types)).batch(32)\n",
        "\n",
        "# Convert the dataset to TensorFlow Dataset\n",
        "train_data = convert_to_dataset(data['Nama'], data['Tipe'])\n",
        "\n",
        "# Create an instance of the FoodRecommenderModel\n",
        "model = FoodRecommenderModel(\n",
        "    num_food_names=len(food_name_vocab.get_vocabulary()),\n",
        "    num_food_types=len(food_type_vocab.get_vocabulary())\n",
        ")\n",
        "\n",
        "# Define the loss function\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# Define the metrics\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs):\n",
        "    food_names, food_types = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model({\"food_names\": food_names, \"food_types\": food_types})\n",
        "        loss_value = loss_object(food_names, logits)\n",
        "    gradients = tape.gradient(loss_value, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    train_loss(loss_value)\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    for inputs in train_data:\n",
        "        train_step(inputs)\n",
        "    print('Epoch {}/{} - Loss: {}'.format(epoch + 1, epochs, train_loss.result()))\n",
        "\n",
        "# Get recommendations for specific food types\n",
        "food_types = ['jajanan']\n",
        "recommendations = get_recommendations_by_types(food_types, similarity_matrix, k=10)\n",
        "print('Recommendations for {}:'.format(', '.join(food_types)))\n",
        "for recommendation in recommendations:\n",
        "    print('- {}'.format(recommendation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5BjCOIbW6yN",
        "outputId": "8b711413-1b16-42b1-a52a-5b88dd997538"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Loss: 7.158131122589111\n",
            "Epoch 2/10 - Loss: 7.154918193817139\n",
            "Epoch 3/10 - Loss: 7.153375148773193\n",
            "Epoch 4/10 - Loss: 7.145746231079102\n",
            "Epoch 5/10 - Loss: 7.092975616455078\n",
            "Epoch 6/10 - Loss: 6.989896774291992\n",
            "Epoch 7/10 - Loss: 6.859889030456543\n",
            "Epoch 8/10 - Loss: 6.726038455963135\n",
            "Epoch 9/10 - Loss: 6.553923606872559\n",
            "Epoch 10/10 - Loss: 6.370954990386963\n",
            "Recommendations for jajanan:\n",
            "- Lemang Tapai\n",
            "- Tela Tela Singkong\n",
            "- Madu Mongso\n",
            "- Ubi Goreng\n",
            "- Banana Roll\n",
            "- Tape Ketan\n",
            "- Kacang Atom (Sukro) Homemade\n",
            "- Kue Talam\n",
            "- Bihun Gulung\n",
            "- Wedang Angsle\n"
          ]
        }
      ]
    }
  ]
}